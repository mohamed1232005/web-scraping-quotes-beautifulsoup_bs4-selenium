# ğŸ•¸ï¸ Web Scraping Quotes with BeautifulSoup & Selenium

[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/)
[![BeautifulSoup](https://img.shields.io/badge/library-BeautifulSoup4-brightgreen)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
[![Selenium](https://img.shields.io/badge/library-Selenium-orange)](https://www.selenium.dev/documentation/)

A complete **Python project** demonstrating **two approaches to web scraping** â€”  
**static parsing** with [BeautifulSoup4 (`bs4`)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)  
and **dynamic browser automation** with [Selenium](https://www.selenium.dev/documentation/) â€”  
on the practice website: [https://quotes.toscrape.com/](https://quotes.toscrape.com/).

This project extracts:
- âœ… **Quote text**
- âœ… **Author name**
- âœ… **Associated tags**

and saves results to **CSV** and **JSONL** for further analysis.

---

## ğŸ“‘ Table of Contents
1. [Project Description](#project-description)
2. [Tech Stack](#tech-stack)
3. [Architecture Overview](#architecture-overview)
4. [Installation](#installation)
5. [Repository Structure](#repository-structure)
9. [Output Format](#output-format)
10. [Comparison: BeautifulSoup vs Selenium](#comparison-beautifulsoup-vs-selenium)
11. [Known Issues & Limitations](#known-issues--limitations)
12. [Future Improvements](#future-improvements)


---

## ğŸ“˜ Project Description
The purpose of this project is to show two industry-standard methods for scraping data:

- **BeautifulSoup (bs4)**:  
  Parses static HTML returned by HTTP requests. Fast, lightweight, and efficient for static pages.

- **Selenium**:  
  Automates a full browser (Chrome). Ideal for scraping pages with heavy **JavaScript rendering**, interactivity, or dynamic content.

The target website is intentionally designed for learning:  
ğŸ‘‰ [https://quotes.toscrape.com/](https://quotes.toscrape.com/)

---

## âš™ï¸ Tech Stack
| Category         | Technology                                                                 |
|------------------|-----------------------------------------------------------------------------|
| Language         | Python 3.8+                                                                 |
| Libraries        | `requests`, `beautifulsoup4`, `selenium`, `webdriver-manager`, `csv`, `json`|
| Browser Driver   | Google Chrome / Chromium + ChromeDriver                                     |
| Output Formats   | CSV, JSONL                                                                  |
| Environment      | Works locally and in Google Colab                                           |

---

## ğŸ—ï¸ Architecture Overview
```text
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  BeautifulSoup Path â”‚      â”‚  Selenium Path                â”‚
 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚ requests â†’ HTML GET â”‚      â”‚ webdriver.Chrome() launch     â”‚
 â”‚ BeautifulSoup parse â”‚      â”‚ Browser automation (headless) â”‚
 â”‚ Extract text/tags   â”‚      â”‚ DOM navigation via selectors  â”‚
 â”‚ Stop after N quotes â”‚      â”‚ Click â€œNextâ€ until N quotes   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                                  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    Save results â†’ CSV / JSONL

```
##ğŸ”§ Installation
-**1. Clone the repository**
git clone https://github.com/your-username/web-scraping-quotes-bs4-selenium.git
cd web-scraping-quotes-bs4-selenium

-**2. Create & activate virtual environment (recommended)**
python3 -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

-**3. Install dependencies**
pip install -r requirements.txt


**requirements.txt**

requests
beautifulsoup4
selenium
webdriver-manager



## ğŸ“‚ Repository Structure
web-scraping-quotes-bs4-selenium/
â”œâ”€â”€ Web Scrapping.ipynb          # implementation
â”œâ”€â”€ README.md              # Documentation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ quotes_10_bs4.csv
â”‚   â”œâ”€â”€ quotes_100_bs4.csv
â”‚   â”œâ”€â”€ quotes_10_selenium.csv
â”‚   â””â”€â”€ quotes_100_selenium.csv



## ğŸ“Š Output Format

-**CSV example:**

text,author,tags
"The world as we have created it is a process of our thinking...",Albert Einstein,change,deep-thoughts,thinking,world
"It is our choices, Harry, that show what we truly are...",J.K. Rowling,abilities,choices


-**JSONL example:**

{"text": "The world as we have created it...", "author": "Albert Einstein", "tags": ["change","deep-thoughts"]}
{"text": "It is our choices, Harry...", "author": "J.K. Rowling", "tags": ["abilities","choices"]}


## ğŸ“ Comparison: BeautifulSoup vs Selenium


| Feature                | BeautifulSoup (bs4)                 | Selenium                                       |
| ---------------------- | ----------------------------------- | ---------------------------------------------- |
| **Speed**              | âš¡ Fast (parses static HTML)         | ğŸ¢ Slower (runs a browser instance)            |
| **Dependencies**       | Lightweight (`requests`, `bs4`)     | Heavy (browser, driver, `selenium`)            |
| **Dynamic JS Content** | âŒ Cannot handle JS rendering        | âœ… Full support (executes JS, clicks, scrolls)  |
| **Use Cases**          | Static websites, APIs, simple pages | Dynamic sites, JS-heavy pages, form automation |



## ğŸš€ Future Improvements

Add unit tests for both scrapers.

Provide a Dockerfile for environment consistency.

Add parallel scraping for speed (async requests).

Implement retry logic & robust error handling.

Extend scrapers to books.toscrape.com for practice.
